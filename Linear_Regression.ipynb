{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pCy7ZouDcRt5",
        "Pu8TFDzQcrSc",
        "iYVH6i-Zey2m"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackqk/sklearn-note/blob/master/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdmXZilEcLLt",
        "colab_type": "text"
      },
      "source": [
        "# **Linear Regrresion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCy7ZouDcRt5",
        "colab_type": "text"
      },
      "source": [
        "# **Least-squares Liner Regression(ordinary least-squares linear regeression)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AguNegACcdlP",
        "colab_type": "code",
        "outputId": "0154896b-c4cf-4822-aeac-7e1f98e40f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=1, n_informative=1, bias=150, noise=30, random_state=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "linreg = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "print(\"linear model coeffient (w):{}\".format(linreg.coef_))\n",
        "print(\"linear model intercept (b):{}\".format(linreg.intercept_))\n",
        "print(\"R-squared score (trainning):{:.3f}\".format(linreg.score(X_train, y_train)))\n",
        "print(\"R-squared score (test):{:.3f}\".format(linreg.score(X_test, y_test)))\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X, y)\n",
        "plt.plot(X, linreg.coef_*X + linreg.intercept_, 'r-')\n",
        "plt.title('Least-squares linear regression')\n",
        "plt.xlabel('Feature value (x)')\n",
        "plt.ylabel('Target value (y)') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear model coeffient (w):[45.70870465]\n",
            "linear model intercept (b):148.44575345658873\n",
            "R-squared score (trainning):0.679\n",
            "R-squared score (test):0.492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Target value (y)')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu8TFDzQcrSc",
        "colab_type": "text"
      },
      "source": [
        "# **Ridge Linear Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciLoJK9ccNnO",
        "colab_type": "text"
      },
      "source": [
        "### 准备数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLPVsDOUcuVb",
        "colab_type": "code",
        "outputId": "e9843abf-683c-4f81-9c26-e8e9079eaee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "crime = pd.read_csv('https://raw.githubusercontent.com/jackqk/sklearn-note/master/data/CommViolPredUnnormalizedData.txt', sep=',', na_values='?')\n",
        "columns_to_keep = [5,6] + list(range(11,26)) + list(range(32, 103))+[145]\n",
        "crime = crime.iloc[:, columns_to_keep].dropna()\n",
        "\n",
        "X_crime = crime.iloc[:, 0:88]\n",
        "y_crime = crime['ViolentCrimesPerPop']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime, random_state = 0)\n",
        "print('Data prepared')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data prepared\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPAN-POMcPIL",
        "colab_type": "text"
      },
      "source": [
        "### Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sED7ANazc3qX",
        "colab_type": "code",
        "outputId": "e60f434c-ff77-4c37-fe76-035630b8b3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime, random_state = 0)\n",
        "linridge = Ridge(alpha=20.0).fit(X_train, y_train)\n",
        "print('ridge regression linear model intercept:{}'.format(linridge.intercept_))\n",
        "print('ridge regression linear model coeff:\\n{}'.format(linridge.coef_))\n",
        "print('R-squared score (training):{:.3f}'.format(linridge.score(X_train, y_train)))\n",
        "print('R-squared score (test):{:.3f}'.format(linridge.score(X_test, y_test)))\n",
        "print('Number of non-zero features:{}'.format(np.sum(linridge.coef_ != 0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ridge regression linear model intercept:-3352.423035846137\n",
            "ridge regression linear model coeff:\n",
            "[ 1.95091438e-03  2.19322667e+01  9.56286607e+00 -3.59178973e+01\n",
            "  6.36465325e+00 -1.96885471e+01 -2.80715856e-03  1.66254486e+00\n",
            " -6.61426604e-03 -6.95450680e+00  1.71944731e+01 -5.62819154e+00\n",
            "  8.83525114e+00  6.79085746e-01 -7.33614221e+00  6.70389803e-03\n",
            "  9.78505502e-04  5.01202169e-03 -4.89870524e+00 -1.79270062e+01\n",
            "  9.17572382e+00 -1.24454193e+00  1.21845360e+00  1.03233089e+01\n",
            " -3.78037278e+00 -3.73428973e+00  4.74595305e+00  8.42696855e+00\n",
            "  3.09250005e+01  1.18644167e+01 -2.05183675e+00 -3.82210450e+01\n",
            "  1.85081589e+01  1.52510829e+00 -2.20086608e+01  2.46283912e+00\n",
            "  3.29328703e-01  4.02228467e+00 -1.12903533e+01 -4.69567413e-03\n",
            "  4.27046505e+01 -1.22507167e-03  1.40795790e+00  9.35041855e-01\n",
            " -3.00464253e+00  1.12390514e+00 -1.82487653e+01 -1.54653407e+01\n",
            "  2.41917002e+01 -1.32497562e+01 -4.20113118e-01 -3.59710660e+01\n",
            "  1.29786751e+01 -2.80765995e+01  4.38513476e+01  3.86590044e+01\n",
            " -6.46024046e+01 -1.63714023e+01  2.90397330e+01  4.15472907e+00\n",
            "  5.34033563e+01  1.98773191e-02 -5.47413979e-01  1.23883518e+01\n",
            "  1.03526583e+01 -1.57238894e+00  3.15887097e+00  8.77757987e+00\n",
            " -2.94724962e+01 -2.32633553e-04  3.13528914e-04 -4.13990258e-04\n",
            " -1.79489212e-04 -5.74054527e-01 -5.17742507e-01 -4.20670931e-01\n",
            "  1.53383594e-01  1.32725423e+00  3.84863158e+00  3.03024594e+00\n",
            " -3.77692644e+01  1.37933464e-01  3.07676522e-01  1.57128807e+01\n",
            "  3.31418306e-01  3.35994414e+00  1.61265911e-01 -2.67619878e+00]\n",
            "R-squared score (training):0.671\n",
            "R-squared score (test):0.494\n",
            "Number of non-zero features:88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPm-YoDac5O5",
        "colab_type": "text"
      },
      "source": [
        "### Ridge Regression with feature scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYtUySeicoCJ",
        "colab_type": "code",
        "outputId": "06151fd0-c324-4aee-eb26-64f1149d107d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "linridge = Ridge(alpha=20).fit(X_train_scaled, y_train)\n",
        "print('ridge regression linear model intercept:{}'.format(linridge.intercept_))\n",
        "print('ridge regression linear model coeff:\\n{}'.format(linridge.coef_))\n",
        "print('R-squared score (training):{:.3f}'.format(linridge.score(X_train_scaled, y_train)))\n",
        "print('R-squared score (test):{:.3f}'.format(linridge.score(X_test_scaled, y_test)))\n",
        "print('Number of non-zero features:{}'.format(np.sum(linridge.coef_ != 0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ridge regression linear model intercept:933.3906385044153\n",
            "ridge regression linear model coeff:\n",
            "[  88.68827454   16.48947987  -50.30285445  -82.90507574  -65.89507244\n",
            "   -2.27674244   87.74108514  150.94862182   18.8802613   -31.05554992\n",
            "  -43.13536109 -189.44266328   -4.52658099  107.97866804  -76.53358414\n",
            "    2.86032762   34.95230077   90.13523036   52.46428263  -62.10898424\n",
            "  115.01780357    2.66942023    6.94331369   -5.66646499 -101.55269144\n",
            "  -36.9087526    -8.7053343    29.11999068  171.25963057   99.36919476\n",
            "   75.06611841  123.63522539   95.24316483 -330.61044265 -442.30179004\n",
            " -284.49744001 -258.37150609   17.66431072 -101.70717151  110.64762887\n",
            "  523.13611718   24.8208959     4.86533322  -30.46775619   -3.51753937\n",
            "   50.57947231   10.84840601   18.27680946   44.11189865   58.33588176\n",
            "   67.08698975  -57.93524659  116.1446052    53.81163718   49.01607711\n",
            "   -7.62262031   55.14288543  -52.08878272  123.39291017   77.12562171\n",
            "   45.49795317  184.91229771  -91.35721203    1.07975971  234.09267451\n",
            "   10.3887921    94.7171829   167.91856631  -25.14025088   -1.18242839\n",
            "   14.60362467   36.77122659   53.19878339  -78.86365997   -5.89858411\n",
            "   26.04790298  115.1534917    68.74143311   68.28588166   16.5260514\n",
            "  -97.90513652  205.20448474   75.97304123   61.3791085   -79.83157049\n",
            "   67.26700741   95.67094538  -11.88380569]\n",
            "R-squared score (training):0.615\n",
            "R-squared score (test):0.599\n",
            "Number of non-zero features:88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gXLBkY3dKTx",
        "colab_type": "text"
      },
      "source": [
        "### select the best Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lFAnNgTdPca",
        "colab_type": "code",
        "outputId": "f1a59fa1-0064-4249-eb63-e2b3c98c7d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "\n",
        "for this_alpha in [0, 1, 10,20, 50, 100, 1000]:\n",
        "  linridge = Ridge(alpha=this_alpha).fit(X_train_scaled, y_train)\n",
        "  r2_train = linridge.score(X_train_scaled, y_train)\n",
        "  r2_test = linridge.score(X_test_scaled, y_test)\n",
        "  num_coeff_bigger = sum(abs(linridge.coef_) > 1.0)\n",
        "  print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, r-squared training: {:.2f}, r-squared test: {:.2f}'\n",
        "         .format(this_alpha, num_coeff_bigger, r2_train, r2_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alpha = 0.00\n",
            "num abs(coeff) > 1.0: 88, r-squared training: 0.67, r-squared test: -425283142331101020684288.00\n",
            "Alpha = 1.00\n",
            "num abs(coeff) > 1.0: 87, r-squared training: 0.66, r-squared test: 0.61\n",
            "Alpha = 10.00\n",
            "num abs(coeff) > 1.0: 87, r-squared training: 0.63, r-squared test: 0.63\n",
            "Alpha = 20.00\n",
            "num abs(coeff) > 1.0: 88, r-squared training: 0.61, r-squared test: 0.62\n",
            "Alpha = 50.00\n",
            "num abs(coeff) > 1.0: 86, r-squared training: 0.58, r-squared test: 0.59\n",
            "Alpha = 100.00\n",
            "num abs(coeff) > 1.0: 87, r-squared training: 0.55, r-squared test: 0.56\n",
            "Alpha = 1000.00\n",
            "num abs(coeff) > 1.0: 84, r-squared training: 0.31, r-squared test: 0.31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYVH6i-Zey2m",
        "colab_type": "text"
      },
      "source": [
        "# **Lasso Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bWGoBdfe1mn",
        "colab_type": "text"
      },
      "source": [
        "### 数据准备"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWYNS2aGhMKR",
        "colab_type": "code",
        "outputId": "f76f62be-e295-4c1b-eeeb-b5037daf4e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "crime = pd.read_csv('https://raw.githubusercontent.com/jackqk/sklearn-note/master/data/CommViolPredUnnormalizedData.txt', sep=',', na_values='?')\n",
        "columns_to_keep = [5,6] + list(range(11,26)) + list(range(32, 103))+[145]\n",
        "crime = crime.iloc[:, columns_to_keep].dropna()\n",
        "\n",
        "X_crime = crime.iloc[:, 0:88]\n",
        "y_crime = crime['ViolentCrimesPerPop']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime, random_state = 0)\n",
        "print('Data prepared')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data prepared\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyF1ZL5biT9y",
        "colab_type": "text"
      },
      "source": [
        "### 观察会有很多0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YRnuFoChNVb",
        "colab_type": "code",
        "outputId": "0c2c01eb-469b-44b8-ccb4-136237084db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        }
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "linlasso = Lasso(alpha=2.0, max_iter = 10000).fit(X_train_scaled, y_train)\n",
        "print('Crime dataset')\n",
        "print('lasso regression linear model intercept: {}'.format(linlasso.intercept_))\n",
        "print('lasso regression linear model coeff:\\n{}'.format(linlasso.coef_))\n",
        "print('Non-zero features: {}'.format(np.sum(linlasso.coef_ != 0)))\n",
        "print('R-squared score (training): {:.3f}'.format(linlasso.score(X_train_scaled, y_train)))\n",
        "print('R-squared score (test): {:.3f}\\n'.format(linlasso.score(X_test_scaled, y_test)))\n",
        "print('Features with non-zero weight (sorted by absolute magnitude):')\n",
        "\n",
        "for e in sorted (list(zip(list(X_crime), linlasso.coef_)), key = lambda e: -abs(e[1])):\n",
        "  if e[1] != 0:\n",
        "    print('\\t{}, {:.3f}'.format(e[0], e[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Crime dataset\n",
            "lasso regression linear model intercept: 1186.612061998579\n",
            "lasso regression linear model coeff:\n",
            "[    0.             0.            -0.          -168.18346054\n",
            "    -0.            -0.             0.           119.6938194\n",
            "     0.            -0.             0.          -169.67564456\n",
            "    -0.             0.            -0.             0.\n",
            "     0.             0.            -0.            -0.\n",
            "     0.            -0.             0.             0.\n",
            "   -57.52991966    -0.            -0.             0.\n",
            "   259.32889226    -0.             0.             0.\n",
            "     0.            -0.         -1188.7396867     -0.\n",
            "    -0.            -0.          -231.42347299     0.\n",
            "  1488.36512229     0.            -0.            -0.\n",
            "    -0.             0.             0.             0.\n",
            "     0.             0.            -0.             0.\n",
            "    20.14419415     0.             0.             0.\n",
            "     0.             0.           339.04468804     0.\n",
            "     0.           459.53799903    -0.             0.\n",
            "   122.69221826    -0.            91.41202242     0.\n",
            "    -0.             0.             0.            73.14365856\n",
            "     0.            -0.             0.             0.\n",
            "    86.35600042     0.             0.             0.\n",
            "  -104.57143405   264.93206555     0.            23.4488645\n",
            "   -49.39355188     0.             5.19775369     0.        ]\n",
            "Non-zero features: 20\n",
            "R-squared score (training): 0.631\n",
            "R-squared score (test): 0.624\n",
            "\n",
            "Features with non-zero weight (sorted by absolute magnitude):\n",
            "\tPctKidsBornNeverMar, 1488.365\n",
            "\tPctKids2Par, -1188.740\n",
            "\tHousVacant, 459.538\n",
            "\tPctPersDenseHous, 339.045\n",
            "\tNumInShelters, 264.932\n",
            "\tMalePctDivorce, 259.329\n",
            "\tPctWorkMom, -231.423\n",
            "\tpctWInvInc, -169.676\n",
            "\tagePct12t29, -168.183\n",
            "\tPctVacantBoarded, 122.692\n",
            "\tpctUrban, 119.694\n",
            "\tMedOwnCostPctIncNoMtg, -104.571\n",
            "\tMedYrHousBuilt, 91.412\n",
            "\tRentQrange, 86.356\n",
            "\tOwnOccHiQuart, 73.144\n",
            "\tPctEmplManu, -57.530\n",
            "\tPctBornSameState, -49.394\n",
            "\tPctForeignBorn, 23.449\n",
            "\tPctLargHouseFam, 20.144\n",
            "\tPctSameCity85, 5.198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ENgmfZQimxd",
        "colab_type": "code",
        "outputId": "e2c79468-bc63-4490-f355-f22cedce8ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "print('Lasso regression: effect of alpha regularization\\n\\\n",
        "parameter on number of features kept in final model\\n')\n",
        "\n",
        "for alpha in [0.5, 1, 2, 3, 5, 10, 20, 50]:\n",
        "    linlasso = Lasso(alpha, max_iter = 10000).fit(X_train_scaled, y_train)\n",
        "    r2_train = linlasso.score(X_train_scaled, y_train)\n",
        "    r2_test = linlasso.score(X_test_scaled, y_test)\n",
        "    \n",
        "    print('Alpha = {:.2f}\\nFeatures kept: {}, r-squared training: {:.2f}, r-squared test: {:.2f}'\n",
        "         .format(alpha, np.sum(linlasso.coef_ != 0), r2_train, r2_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lasso regression: effect of alpha regularization\n",
            "parameter on number of features kept in final model\n",
            "\n",
            "Alpha = 0.50\n",
            "Features kept: 35, r-squared training: 0.65, r-squared test: 0.58\n",
            "Alpha = 1.00\n",
            "Features kept: 25, r-squared training: 0.64, r-squared test: 0.60\n",
            "Alpha = 2.00\n",
            "Features kept: 20, r-squared training: 0.63, r-squared test: 0.62\n",
            "Alpha = 3.00\n",
            "Features kept: 17, r-squared training: 0.62, r-squared test: 0.63\n",
            "Alpha = 5.00\n",
            "Features kept: 12, r-squared training: 0.60, r-squared test: 0.61\n",
            "Alpha = 10.00\n",
            "Features kept: 6, r-squared training: 0.57, r-squared test: 0.58\n",
            "Alpha = 20.00\n",
            "Features kept: 2, r-squared training: 0.51, r-squared test: 0.50\n",
            "Alpha = 50.00\n",
            "Features kept: 1, r-squared training: 0.31, r-squared test: 0.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3HLISu-qUqS",
        "colab_type": "text"
      },
      "source": [
        "# **Polynomial Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTwbJTFwqaJb",
        "colab_type": "text"
      },
      "source": [
        "### 准备数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BaTlHorrmm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_friedman1\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_F1, y_F1 = make_friedman1(n_samples = 100, n_features = 7, random_state = 0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_F1, y_F1, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2DFyXResJlZ",
        "colab_type": "text"
      },
      "source": [
        "### 以Least-squared Linear Regression为比较对象"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHbJRmS7saBh",
        "colab_type": "code",
        "outputId": "217571d0-d337-48b8-a274-724db93a9a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "linreg = LinearRegression().fit(X_train, y_train)\n",
        "print('linear model coeff (w): {}'.format(linreg.coef_))\n",
        "print('linear model intercept (b): {:.3f}'.format(linreg.intercept_))\n",
        "print('R-squared score (training): {:.3f}'.format(linreg.score(X_train, y_train)))\n",
        "print('R-squared score (test): {:.3f}'.format(linreg.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear model coeff (w): [ 4.42036739  5.99661447  0.52894712 10.23751345  6.5507973  -2.02082636\n",
            " -0.32378811]\n",
            "linear model intercept (b): 1.543\n",
            "R-squared score (training): 0.722\n",
            "R-squared score (test): 0.722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDD_xRsJtAUp",
        "colab_type": "text"
      },
      "source": [
        "### Polynomial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9IeWltQs2_v",
        "colab_type": "code",
        "outputId": "209fec57-f9f4-4007-d4ce-ecbebf777b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "print('\\nNow we transform the original input data to add\\n\\\n",
        "polynomial features up to degree 2 (quadratic)\\n')\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_F1_poly = poly.fit_transform(X_F1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_F1_poly, y_F1, random_state = 0)\n",
        "linreg = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "print('(poly deg 2) linear model coeff (w):\\n{}'.format(linreg.coef_))\n",
        "print('(poly deg 2) linear model intercept (b): {:.3f}'.format(linreg.intercept_))\n",
        "print('(poly deg 2) R-squared score (training): {:.3f}'.format(linreg.score(X_train, y_train)))\n",
        "print('(poly deg 2) R-squared score (test): {:.3f}\\n'.format(linreg.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Now we transform the original input data to add\n",
            "polynomial features up to degree 2 (quadratic)\n",
            "\n",
            "(poly deg 2) linear model coeff (w):\n",
            "[ 3.40951018e-12  1.66452443e+01  2.67285381e+01 -2.21348316e+01\n",
            "  1.24359227e+01  6.93086826e+00  1.04772675e+00  3.71352773e+00\n",
            " -1.33785505e+01 -5.73177185e+00  1.61813184e+00  3.66399592e+00\n",
            "  5.04513181e+00 -1.45835979e+00  1.95156872e+00 -1.51297378e+01\n",
            "  4.86762224e+00 -2.97084269e+00 -7.78370522e+00  5.14696078e+00\n",
            " -4.65479361e+00  1.84147395e+01 -2.22040650e+00  2.16572630e+00\n",
            " -1.27989481e+00  1.87946559e+00  1.52962716e-01  5.62073813e-01\n",
            " -8.91697516e-01 -2.18481128e+00  1.37595426e+00 -4.90336041e+00\n",
            " -2.23535458e+00  1.38268439e+00 -5.51908208e-01 -1.08795007e+00]\n",
            "(poly deg 2) linear model intercept (b): -3.206\n",
            "(poly deg 2) R-squared score (training): 0.969\n",
            "(poly deg 2) R-squared score (test): 0.805\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGQ9psKgs-CN",
        "colab_type": "text"
      },
      "source": [
        "### Polynomial + Ridge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMJA7xmatImZ",
        "colab_type": "code",
        "outputId": "4847baeb-9de6-45c1-86a5-460ef286b105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "print('\\nAddition of many polynomial features often leads to\\n\\\n",
        "overfitting, so we often use polynomial features in combination\\n\\\n",
        "with regression that has a regularization penalty, like ridge\\n\\\n",
        "regression.\\n')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_F1_poly, y_F1, random_state = 0)\n",
        "linreg = Ridge().fit(X_train, y_train)\n",
        "\n",
        "print('(poly deg 2 + ridge) linear model coeff (w):\\n{}'.format(linreg.coef_))\n",
        "print('(poly deg 2 + ridge) linear model intercept (b): {:.3f}'.format(linreg.intercept_))\n",
        "print('(poly deg 2 + ridge) R-squared score (training): {:.3f}'.format(linreg.score(X_train, y_train)))\n",
        "print('(poly deg 2 + ridge) R-squared score (test): {:.3f}'.format(linreg.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Addition of many polynomial features often leads to\n",
            "overfitting, so we often use polynomial features in combination\n",
            "with regression that has a regularization penalty, like ridge\n",
            "regression.\n",
            "\n",
            "(poly deg 2 + ridge) linear model coeff (w):\n",
            "[ 0.          2.229281    4.73349734 -3.15432089  3.8585194   1.60970912\n",
            " -0.76967054 -0.14956002 -1.75215371  1.5970487   1.37080607  2.51598244\n",
            "  2.71746523  0.48531538 -1.9356048  -1.62914955  1.51474518  0.88674141\n",
            "  0.26141199  2.04931775 -1.93025705  3.61850966 -0.71788143  0.63173956\n",
            " -3.16429847  1.29161448  3.545085    1.73422041  0.94347654 -0.51207219\n",
            "  1.70114448 -1.97949067  1.80687548 -0.2173863   2.87585898 -0.89423157]\n",
            "(poly deg 2 + ridge) linear model intercept (b): 5.418\n",
            "(poly deg 2 + ridge) R-squared score (training): 0.826\n",
            "(poly deg 2 + ridge) R-squared score (test): 0.825\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}